# Multi-architecture build stage
# For standard build, use: docker build -t k13s .
# For pre-built binary, use: docker build -f Dockerfile.prebuilt -t k13s .
#
# Air-gapped/Offline environment:
# 1. Build image on a machine with internet access
# 2. Save: docker save k13s:latest | gzip > k13s.tar.gz
# 3. Transfer to air-gapped environment
# 4. Load: docker load < k13s.tar.gz
#
# Usage in Kubernetes (air-gapped):
# - Ensure image is available in local registry
# - Set imagePullPolicy: IfNotPresent or Never
# - Configure LLM endpoint to internal Ollama/vLLM server

FROM golang:1.25.5-alpine AS builder

# Install build dependencies
RUN apk add --no-cache git ca-certificates tzdata

# Set working directory
WORKDIR /app

# Copy go mod files first for better caching
COPY go.mod go.sum ./
ENV GOTOOLCHAIN=auto
RUN go mod download

# Copy source code
COPY . .

# Build the binary
RUN CGO_ENABLED=0 go build \
    -ldflags="-w -s -X main.version=$(git describe --tags --always --dirty 2>/dev/null || echo 'dev')" \
    -o k13s ./cmd/kube-ai-dashboard-cli/main.go

# Final stage
FROM alpine:3.21

# Install runtime dependencies
# - ncurses: Required for TUI mode (terminal UI)
# - ca-certificates: For HTTPS connections
# - tzdata: For timezone support
# - curl: For health checks
RUN apk add --no-cache ca-certificates tzdata curl ncurses

# Create non-root user
RUN adduser -D -g '' k13s

# Copy binary from builder
COPY --from=builder /app/k13s /usr/local/bin/k13s

# Create config and kubeconfig directories
RUN mkdir -p /home/k13s/.config/k13s /home/k13s/.kube && \
    chown -R k13s:k13s /home/k13s

# Switch to non-root user
USER k13s
WORKDIR /home/k13s

# Environment variables for configuration
# K13S_AUTH_MODE: token (k8s RBAC - recommended) or local (username/password)
# K13S_USERNAME/K13S_PASSWORD: credentials for local auth mode (optional)
# KUBECONFIG: path to kubeconfig file (mount as volume)
# K13S_LLM_PROVIDER: openai, ollama, gemini, anthropic, bedrock
# K13S_LLM_ENDPOINT: Custom LLM endpoint (e.g., http://ollama:11434 for air-gapped)
# K13S_LLM_MODEL: Model name (e.g., gpt-4o-mini, llama3)
# K13S_LLM_API_KEY: API key for LLM provider
ENV K13S_PORT=8080 \
    K13S_AUTH_MODE=token \
    K13S_LLM_PROVIDER=ollama \
    K13S_LLM_MODEL=llama3 \
    K13S_LLM_ENDPOINT=""

# Expose web UI port
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -sf http://localhost:${K13S_PORT}/api/health || exit 1

# Default command: run in web mode
# TUI mode: docker run -it --rm -v ~/.kube/config:/home/k13s/.kube/config:ro k13s -tui
# Web mode: docker run -d -p 8080:8080 -v ~/.kube/config:/home/k13s/.kube/config:ro k13s
ENTRYPOINT ["/usr/local/bin/k13s"]
CMD ["-web", "-port", "8080"]
